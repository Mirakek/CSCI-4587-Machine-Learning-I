{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression/Chapter02 - HandsOn Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read X.txt\n",
    "# It usually works without the \"lineterminator='\\n'\" option\n",
    "X=pd.read_csv(\"./HousingData/X.txt\",sep='\\t', lineterminator='\\n', header=None )\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Y.txt\n",
    "y=pd.read_csv(\"./HousingData/Y.txt\", header=None )\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least Squares: Linear Regression\n",
    "Performing Linear Regression using Scikit-Learn is simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input X should not have the X0=1 column in it, so, we drop it and create and use X2.\n",
    "X2 = X.drop([0], axis=1)\n",
    "X2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X2, y)\n",
    "lin_reg.intercept_, lin_reg.coef_ # Note how the intercept and the rest of the coefficients are returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `LinearRegression` class is based on the `scipy.linalg.lstsq()` function (the name `linalg` stands for \"**linear algebra**\" and `lstsq()` stands for “**least squares**”), which you could call directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can predict the house-price for the Query, Q=[5 3 2500], that is a house having 5 bedrooms, 3 bathrooms and 2500 sqft living area as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = pd.DataFrame([[5,3,2500]])  \n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg.predict(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Normal Equation\n",
    "To find the value of **Beta** that minimizes the cost or error function, we can use a *closed-form* solution - in other words, a mathematical equation that gives the result directly. This is called the *Normal Equation*, expresses as $ Beta = (X^T X)^{-1} X^T y$.\n",
    "\n",
    "We will use the `inv()` function from NumPy’s linear algebra module (`np.linalg`) to compute the inverse of a matrix, and the `dot()` method for matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Beta = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "Beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to use *pseudoinverse*, you can use `np.linalg.pinv()` as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.pinv(X.T.dot(X)).dot(X.T).dot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use Beta for prediction. \n",
    "* For a Query, Q=[1 5 3 2500], that is a house having 5 bedrooms, 3 bathrooms and 2500 sqft living area,  for example, \n",
    "    - we can predict the house price by: Q*Beta;    \n",
    "    - which should return 2.1384e+005 or, 213,840\n",
    "\n",
    "Note: Q is in row form and Beta is in column form. Thus, we do `Q*Beta` instead of `Q.T*Beta`. And the '1' indicates $X_0$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q= np.array([1,5,3, 2500])\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q.dot(Beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Information\n",
    "Now, assume the matrix X did not have *X0*=1 column inserted and we need to insert it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_cnt=X.shape[0]\n",
    "R_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`np.c_` is array concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.c_[np.ones((R_cnt,1)), X]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
