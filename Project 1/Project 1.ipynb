{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "3e572813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score, KFold, cross_val_predict\n",
    "from sklearn.metrics import (accuracy_score, balanced_accuracy_score,\n",
    "                             matthews_corrcoef, recall_score, f1_score,\n",
    "                             confusion_matrix, precision_score, classification_report)\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee6e0f1",
   "metadata": {},
   "source": [
    "# 0) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "aa044065",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r'C:\\Users\\brand\\OneDrive - University of New Orleans\\Fall 2023\\Machine Learning I\\Project 1\\iris.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4618068",
   "metadata": {},
   "source": [
    "# 1) Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "bf0dcfc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETC: 0.9400 (+/- 0.0629)\n",
      "Bagging: 0.9467 (+/- 0.0499)\n",
      "DTC: 0.9467 (+/- 0.0581)\n",
      "LR: 0.9533 (+/- 0.0670)\n",
      "SVC: 0.9600 (+/- 0.0533)\n",
      "kNN: 0.9533 (+/- 0.0670)\n"
     ]
    }
   ],
   "source": [
    "# Running 10 Fold cross-validations for the listed classifiers\n",
    "classifiers = {\n",
    "    \"ETC\": ExtraTreeClassifier(),\n",
    "    \"Bagging\": BaggingClassifier(),\n",
    "    \"DTC\": DecisionTreeClassifier(),\n",
    "    \"LR\": LogisticRegression(max_iter=1000),\n",
    "    \"SVC\": SVC(),\n",
    "    \"kNN\": KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "for name, classifier in classifiers.items():\n",
    "    cv_score = cross_val_score(classifier, X, y, cv=kf, scoring='accuracy')\n",
    "    print(f\"{name}: {cv_score.mean():.4f} (+/- {cv_score.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b8663b",
   "metadata": {},
   "source": [
    "# 2) Class-wise Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1ad1ddd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Had to create my own function since the specificity function was bugging out for each class\n",
    "def specificity_per_class(cm, label_index):\n",
    "\n",
    "    true_negative = np.delete(np.delete(cm, label_index, axis=0), label_index, axis=1).sum()\n",
    "    false_positive = np.delete(cm, label_index, axis=0)[:, label_index].sum()\n",
    "    \n",
    "    return true_negative / (true_negative + false_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "6251b727",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ETC: 0.9267 (+/- 0.0467)\n",
      "Accuracy: 0.9467\n",
      "Balanced Accuracy: 0.9467\n",
      "Matthews Correlation Coefficient: 0.9202\n",
      "Confusion Matrix:\n",
      "[[50  0  0]\n",
      " [ 0 45  5]\n",
      " [ 0  3 47]]\n",
      "\n",
      "Class-wise metrics:\n",
      "\n",
      "Label: Iris-setosa\n",
      "Sensitivity/Recall: 1.0000\n",
      "F1-score: 1.0000\n",
      "\n",
      "Label: Iris-versicolor\n",
      "Sensitivity/Recall: 0.9000\n",
      "F1-score: 0.9184\n",
      "\n",
      "Label: Iris-virginica\n",
      "Sensitivity/Recall: 0.9400\n",
      "F1-score: 0.9216\n",
      "Specificity for class 0: 1.0000\n",
      "Specificity for class 1: 0.9700\n",
      "Specificity for class 2: 0.9500\n",
      "\n",
      "Bagging: 0.9467 (+/- 0.0653)\n",
      "Accuracy: 0.9533\n",
      "Balanced Accuracy: 0.9533\n",
      "Matthews Correlation Coefficient: 0.9301\n",
      "Confusion Matrix:\n",
      "[[50  0  0]\n",
      " [ 0 47  3]\n",
      " [ 0  4 46]]\n",
      "\n",
      "Class-wise metrics:\n",
      "\n",
      "Label: Iris-setosa\n",
      "Sensitivity/Recall: 1.0000\n",
      "F1-score: 1.0000\n",
      "\n",
      "Label: Iris-versicolor\n",
      "Sensitivity/Recall: 0.9400\n",
      "F1-score: 0.9307\n",
      "\n",
      "Label: Iris-virginica\n",
      "Sensitivity/Recall: 0.9200\n",
      "F1-score: 0.9293\n",
      "Specificity for class 0: 1.0000\n",
      "Specificity for class 1: 0.9600\n",
      "Specificity for class 2: 0.9700\n",
      "\n",
      "DTC: 0.9400 (+/- 0.0757)\n",
      "Accuracy: 0.9467\n",
      "Balanced Accuracy: 0.9467\n",
      "Matthews Correlation Coefficient: 0.9200\n",
      "Confusion Matrix:\n",
      "[[50  0  0]\n",
      " [ 0 46  4]\n",
      " [ 0  4 46]]\n",
      "\n",
      "Class-wise metrics:\n",
      "\n",
      "Label: Iris-setosa\n",
      "Sensitivity/Recall: 1.0000\n",
      "F1-score: 1.0000\n",
      "\n",
      "Label: Iris-versicolor\n",
      "Sensitivity/Recall: 0.9200\n",
      "F1-score: 0.9200\n",
      "\n",
      "Label: Iris-virginica\n",
      "Sensitivity/Recall: 0.9200\n",
      "F1-score: 0.9200\n",
      "Specificity for class 0: 1.0000\n",
      "Specificity for class 1: 0.9600\n",
      "Specificity for class 2: 0.9600\n",
      "\n",
      "LR: 0.9533 (+/- 0.0427)\n",
      "Accuracy: 0.9600\n",
      "Balanced Accuracy: 0.9600\n",
      "Matthews Correlation Coefficient: 0.9400\n",
      "Confusion Matrix:\n",
      "[[50  0  0]\n",
      " [ 0 47  3]\n",
      " [ 0  3 47]]\n",
      "\n",
      "Class-wise metrics:\n",
      "\n",
      "Label: Iris-setosa\n",
      "Sensitivity/Recall: 1.0000\n",
      "F1-score: 1.0000\n",
      "\n",
      "Label: Iris-versicolor\n",
      "Sensitivity/Recall: 0.9400\n",
      "F1-score: 0.9400\n",
      "\n",
      "Label: Iris-virginica\n",
      "Sensitivity/Recall: 0.9400\n",
      "F1-score: 0.9400\n",
      "Specificity for class 0: 1.0000\n",
      "Specificity for class 1: 0.9700\n",
      "Specificity for class 2: 0.9700\n",
      "\n",
      "SVC: 0.9667 (+/- 0.0333)\n",
      "Accuracy: 0.9667\n",
      "Balanced Accuracy: 0.9667\n",
      "Matthews Correlation Coefficient: 0.9501\n",
      "Confusion Matrix:\n",
      "[[50  0  0]\n",
      " [ 0 48  2]\n",
      " [ 0  3 47]]\n",
      "\n",
      "Class-wise metrics:\n",
      "\n",
      "Label: Iris-setosa\n",
      "Sensitivity/Recall: 1.0000\n",
      "F1-score: 1.0000\n",
      "\n",
      "Label: Iris-versicolor\n",
      "Sensitivity/Recall: 0.9600\n",
      "F1-score: 0.9505\n",
      "\n",
      "Label: Iris-virginica\n",
      "Sensitivity/Recall: 0.9400\n",
      "F1-score: 0.9495\n",
      "Specificity for class 0: 1.0000\n",
      "Specificity for class 1: 0.9700\n",
      "Specificity for class 2: 0.9800\n",
      "\n",
      "kNN: 0.9467 (+/- 0.0653)\n",
      "Accuracy: 0.9467\n",
      "Balanced Accuracy: 0.9467\n",
      "Matthews Correlation Coefficient: 0.9202\n",
      "Confusion Matrix:\n",
      "[[50  0  0]\n",
      " [ 0 47  3]\n",
      " [ 0  5 45]]\n",
      "\n",
      "Class-wise metrics:\n",
      "\n",
      "Label: Iris-setosa\n",
      "Sensitivity/Recall: 1.0000\n",
      "F1-score: 1.0000\n",
      "\n",
      "Label: Iris-versicolor\n",
      "Sensitivity/Recall: 0.9400\n",
      "F1-score: 0.9216\n",
      "\n",
      "Label: Iris-virginica\n",
      "Sensitivity/Recall: 0.9000\n",
      "F1-score: 0.9184\n",
      "Specificity for class 0: 1.0000\n",
      "Specificity for class 1: 0.9500\n",
      "Specificity for class 2: 0.9700\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "\n",
    "for name, classifier in classifiers.items():\n",
    "    # Calculating cross-validated scores\n",
    "    cv_score = cross_val_score(classifier, X, y, cv=kf, scoring='accuracy')\n",
    "    print(f\"\\n{name}: {cv_score.mean():.4f} (+/- {cv_score.std():.4f})\")\n",
    "\n",
    "    # Getting cross-validated predictions\n",
    "    y_pred = cross_val_predict(classifier, X, y, cv=kf)\n",
    "    \n",
    "    # Calculating metrics\n",
    "    acc = accuracy_score(y, y_pred)\n",
    "    bal_acc = balanced_accuracy_score(y, y_pred)\n",
    "    mcc = matthews_corrcoef(y, y_pred)\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    cr = classification_report(y, y_pred, target_names=y.unique(), output_dict=True)\n",
    "    \n",
    "    # Displaying metrics\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"Balanced Accuracy: {bal_acc:.4f}\")\n",
    "    print(f\"Matthews Correlation Coefficient: {mcc:.4f}\")\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    print(\"\\nClass-wise metrics:\")\n",
    "    for label, metrics in cr.items():\n",
    "        if label in y.unique():\n",
    "            print(f\"\\nLabel: {label}\")\n",
    "            print(f\"Sensitivity/Recall: {metrics['recall']:.4f}\")\n",
    "            print(f\"F1-score: {metrics['f1-score']:.4f}\")\n",
    "    labels_indices = range(len(cm))  # assuming cm is square\n",
    "\n",
    "    for label_index in labels_indices:\n",
    "        spec = specificity_per_class(cm, label_index)\n",
    "        print(f\"Specificity for class {label_index}: {spec:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba3f97a",
   "metadata": {},
   "source": [
    "# 3) Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b30b9ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics evaluation function\n",
    "def evaluate_metrics(y_true, y_pred):\n",
    "    # Compute Sensitivity and Specificity for multiclass\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    FP = cm.sum(axis=0) - np.diag(cm)  \n",
    "    FN = cm.sum(axis=1) - np.diag(cm)\n",
    "    TP = np.diag(cm)\n",
    "    TN = cm.sum() - (FP + FN + TP)\n",
    "    \n",
    "    # Sensitivity\n",
    "    TPR = TP / (TP + FN)\n",
    "    sensitivity = np.mean(TPR)\n",
    "    \n",
    "    # Specificity\n",
    "    TNR = TN / (TN + FP)\n",
    "    specificity = np.mean(TNR)\n",
    "    \n",
    "    metrics = {\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"Balanced Accuracy\": balanced_accuracy_score(y_true, y_pred),\n",
    "        \"Matthews Correlation Coefficient\": matthews_corrcoef(y_true, y_pred),\n",
    "        \"Sensitivity\": sensitivity,\n",
    "        \"Specificity\": specificity,\n",
    "        \"F1-Score\": f1_score(y_true, y_pred, average='macro'),\n",
    "        \"Confusion Matrix\": cm\n",
    "    }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "3511647f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9333\n",
      "Balanced Accuracy: 0.9444\n",
      "Matthews Correlation Coefficient: 0.9055\n",
      "Sensitivity: 0.9444\n",
      "Specificity: 0.9710\n",
      "F1-Score: 0.9280\n",
      "Confusion Matrix:\n",
      "[[11  0  0]\n",
      " [ 0 10  2]\n",
      " [ 0  0  7]]\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.9667\n",
      "Balanced Accuracy: 0.9722\n",
      "Matthews Correlation Coefficient: 0.9509\n",
      "Sensitivity: 0.9722\n",
      "Specificity: 0.9855\n",
      "F1-Score: 0.9633\n",
      "Confusion Matrix:\n",
      "[[11  0  0]\n",
      " [ 0 11  1]\n",
      " [ 0  0  7]]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Base classifiers and meta classifiers for the stacking models\n",
    "base_classifiers_1 = [('ETC', ExtraTreeClassifier()),\n",
    "                      ('Bagging', BaggingClassifier()),\n",
    "                      ('DTC', DecisionTreeClassifier())]\n",
    "\n",
    "base_classifiers_2 = [('LR', LogisticRegression(max_iter=1000)),\n",
    "                      ('SVC', SVC(probability=True)),\n",
    "                      ('kNN', KNeighborsClassifier())]\n",
    "\n",
    "meta_classifier_1 = LogisticRegression(max_iter=1000)\n",
    "meta_classifier_2 = DecisionTreeClassifier()\n",
    "\n",
    "# Construct the two stacked classifiers\n",
    "stacking_clf_1 = StackingClassifier(estimators=base_classifiers_1, final_estimator=meta_classifier_1, stack_method='predict_proba')\n",
    "stacking_clf_2 = StackingClassifier(estimators=base_classifiers_2, final_estimator=meta_classifier_2, stack_method='predict_proba')\n",
    "\n",
    "# Training both\n",
    "for clf in [stacking_clf_1, stacking_clf_2]:\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    metrics = evaluate_metrics(y_test, y_pred)\n",
    "    for metric_name, metric_value in metrics.items():\n",
    "        if metric_name != \"Confusion Matrix\":\n",
    "            print(f\"{metric_name}: {metric_value:.4f}\")\n",
    "        else:\n",
    "            print(f\"{metric_name}:\\n{metric_value}\")\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
